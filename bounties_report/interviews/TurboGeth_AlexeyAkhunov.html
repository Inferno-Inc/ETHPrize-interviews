<link rel="stylesheet" href="../styles/main.css">

<h2>Alexey Akhunov</h2>


<p>
Sina on 1/11/2018.
</p><ol>

<li><strong>What type of apps do you build:</strong> <ol>

 <li><strong>Eg: Are they primarily blockchain-based? Blockchain backend with a "regular" web front-end? Front-end that uses the blockchain directly via Metamask et al?</strong>
 <li>Been in Ethereum since the beginning. Was following the PoC. Mined few blocks on his home computer. 
 <li>Initially ran geth, then parity, then geth again.   <ol>

  <li>Geth said it would be more like a library.
 <li>6 months ago, moved to doing Ethereum dev full time.  <ol>

  <li>Did security audits – gets tedious – smart contract are usually short. But comes with more stuff – server-side, etc
  <li>Now: playing with the go-ethereum code, trying to optimize it.   <ol>

   <li>People talk about sharding, Casper, etc will fix everything; but that won't solve everything without optimizing everything.
<li><strong>Brief walk through of the tools you use daily</strong> <ol>

 <li><strong>If not already mentioned, are there any libraries you rely on regularly?</strong>
 <li>Geth.  <ol>

  <li>Can pass in --cpu-profile
  <li>Uses basic stuff that comes with Go: PProf.
  <li>Go has in-built tool to open this file.
  <li>Can generate dominator tree -> whole graph of traces vs times. Shows which nodes are dominating.
 <li>His workflow:  <ol>

  <li>1) Change code.
  <li>2) Run geth with --cpu-prof
  <li>3) Generate graph from .prof file.
  <li>4) Run on cloud overnight.
<li><strong>Who are other people you think we should talk to?</strong> <ol>

 <li>Nick Johnson
 <li>Peter from Geth.
 <li>Quickblocks founder – Jay Rush – quick access to blockchain data. Working on the problem of quick state download.
<li><strong>Other bounties:</strong> <ol>

 <li>Unification of testnets.  <ol>

  <li>Rinkeby & Kovan are still incompatible.   <ol>

   <li>I wanted to write this myself, write Kovan implementation in Geth?
 <li>I hate that everything in the smart-contract ecosystem is written in Javascript – e.g. Truffle. People then use truffle bindings in production.  <ol>

  <li>Native go tooling. Native go contracts.
  <li>I tried to do javascript auditing. And it is virtually impossible without safety of types. There's a lot of dependencies; it's really hard to check everything.
  <li>Specific: where the web-server is written, not in JS, but in a compiled language: should bind directly to the smart contracts, instead of going through JS bindings. Use go-bindings.
<li><strong>What pisses you off:</strong> <ol>

 <li>Yesterday – spent 3 hours!!! – fixing compiler errors. The codebase is large.  <ol>

  <li>Added an extra flag to switch db to another from LevelDB. Compiling errors in fast-sync and light-client.
  <li>Codebase has a lot of baggage: Geth has Whisper, Swarm, and light-client.   <ol>

   <li>Do geth developers want to separate these out?
   <li>Potential concurrencies & SSD improvements.
<li><strong>Misc:</strong> <ol>

 <li>Optimizing Geth:  <ol>

  <li>It all started with a rough kinda experiment – in November network became congested –   <ol>

   <li>Started doing profiling in Go. Learned to do it then.    <ol>

    <li>Saw that geth was mostly talking with LevelDB database.
  <li>The process:   <ol>

   <li>1) look at the profile
   <li>2) ask questions – why is it slow?
   <li>3) then look at code, edit, experiment to improve.
  <li>The system is complex – hundreds of goroutines running at the same time.   <ol>

   <li>Trying to optimize the state management. State is constantly growing. Things will have to be written on disk; fetching it again will be slow. Can have cache, but what if it's outside of the cache.    <ol>

    <li>Problem 1) speed of processing.
    <li>Problem 2) if you're running a full node –      <ol>

     <li>Fast-sync: download all the headers + download enough state objects from other peers to only verify randomly selected blocks.      <ol>

      <li>Then, after this, you become a full sync node.
      <li>Whole state from beginning is ~ 600GB.
     <li>It needs to be compressed.
  <li>How do you test your optimizations:   <ol>

   <li>Peter from Geth told him: you can export the blocks, run through your node without being connected to network, and process.
  <li>Jameson Lopp:   <ol>

   <li>His criteria for a blockchain: how quickly it syncs.
  <li>Idea for bounties:   <ol>

   <li>Shared resource: have block data sliced up into pieces (e.g. first 100k blocks, second 100k blocks etc.), give it a Github branch, spin up the image, it does a git pull, launches an instance of the client without p2p mode, imports this part of the blockchain, does comparison across different parts (e.g. when there was a spam attack in ~2.4m block)    <ol>

    <li>My goal: to go through spam blocks really quickly. Every sync should be very fast.
  <li>People complaining (e.g. exchanges) that they can't keep up with the blockchain – e.g. Etherscan – falling behind. The clients are becoming inefficient. Instability problems. "When quantitative changes become qualitative" – breaking points are hit.
  <li>Go-ethereum developers are also working on this – I do the same – but I like not having the responsibility and just hacking around.
  <li>Collaborations between different clients: Parity & Geth   <ol>

   <li>Parity had a great breakthrough – how to tune parameters of database – can sync on HDD. I'm hoping that collaborations will grow. State management across clients is important.</li>   </ol>
